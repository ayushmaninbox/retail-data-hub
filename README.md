<p align="center">
  <h1 align="center">ğŸ§  Retail Data Hub</h1>
  <p align="center">
    <strong>Smart Retail Supply Chain & Customer Intelligence Platform</strong>
  </p>
  <p align="center">
    A full-stack data engineering project demonstrating ETL pipelines, Medallion Architecture, star schema modeling, automated data quality, KPI analytics, a FastAPI backend, and an interactive Next.js dashboard â€” all at zero infrastructure cost.
  </p>
</p>

---

## âœ¨ Highlights

| Capability | Implementation |
|---|---|
| **Architecture** | Medallion (Raw â†’ Bronze â†’ Silver â†’ Gold) with Parquet storage |
| **Data Modeling** | Star schema with fact & dimension tables, SCD Type 2 |
| **Ingestion** | Batch (CSV) + near real-time (JSON) with schema validation & retry |
| **Data Quality** | 7 automated checks with JSON evidence reports |
| **Analytics** | Commercial, Operations, Customer KPIs + Market Basket (Apriori) |
| **API** | FastAPI backend serving Gold layer KPIs with Swagger docs |
| **Dashboard** | 7-page interactive Next.js app with Recharts, Tailwind CSS |
| **Query Engine** | DuckDB â€” in-process SQL directly on Parquet files |
| **Cost** | $0 â€” Python + DuckDB + Next.js |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA SOURCES                             â”‚
â”‚  POS Sales (CSV)  Â·  Web Orders (JSON)  Â·  Warehouse (CSV)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚              â”‚              â”‚
               â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥‰ BRONZE â€” Raw Parquet (schema-validated, append-only)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚  clean Â· deduplicate Â· merge
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥ˆ SILVER â€” Cleaned & unified sales data                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚  star schema Â· SCD2 Â· surrogate keys
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¥‡ GOLD â€” Star Schema (facts + dimensions, partitioned)        â”‚
â”‚  dim_date Â· dim_product Â· dim_store Â· dim_customer Â· fact_sales â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â–¼               â–¼               â–¼
       ğŸ“ˆ KPI Scripts    ğŸš€ FastAPI       ğŸ“Š Next.js
        (Python)        (REST API)        Dashboard
                             â”‚
                             â””â”€â”€â”€â”€ serves JSON â”€â”€â”€â”€â–¶ ğŸ–¥ï¸ Dashboard
```

---

## ğŸ“‚ Project Structure

```
retail-data-hub/
â”‚
â”œâ”€â”€ data/                              # All data layers
â”‚   â”œâ”€â”€ raw/                           # Source files (CSV, JSON)
â”‚   â”œâ”€â”€ bronze/                        # Ingested Parquet (schema-validated)
â”‚   â”œâ”€â”€ silver/                        # Cleaned & merged Parquet
â”‚   â”œâ”€â”€ gold/                          # Star schema Parquet (partitioned)
â”‚   â”œâ”€â”€ analytics/                     # KPI output (JSON files)
â”‚   â””â”€â”€ logs/                          # Pipeline execution logs
â”‚
â”œâ”€â”€ src/                               # All pipeline & analytics code
â”‚   â”œâ”€â”€ data_generation/               # Synthetic data generators
â”‚   â”‚   â”œâ”€â”€ generate_pos.py            #   POS sales (Faker, 10 Indian cities)
â”‚   â”‚   â”œâ”€â”€ generate_web_orders.py     #   Web orders (JSON)
â”‚   â”‚   â””â”€â”€ generate_warehouse.py      #   Warehouse inventory (CSV)
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/                     # Raw â†’ Bronze layer
â”‚   â”‚   â”œâ”€â”€ ingest_batch.py            #   Batch CSV ingestion
â”‚   â”‚   â”œâ”€â”€ ingest_realtime.py         #   Near real-time JSON ingestion
â”‚   â”‚   â””â”€â”€ schema_validator.py        #   Schema validation & enforcement
â”‚   â”‚
â”‚   â”œâ”€â”€ transformation/                # Bronze â†’ Silver â†’ Gold
â”‚   â”‚   â”œâ”€â”€ bronze_to_silver.py        #   Cleaning, dedup, merging
â”‚   â”‚   â”œâ”€â”€ silver_to_gold.py          #   Star schema construction
â”‚   â”‚   â””â”€â”€ scd_handler.py             #   SCD Type 2 implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ quality/                       # Data Quality framework
â”‚   â”‚   â””â”€â”€ quality_checks.py          #   7 automated DQ checks + JSON report
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/                     # KPI computation scripts
â”‚   â”‚   â”œâ”€â”€ commercial_kpis.py         #   Revenue, cities, products, channels
â”‚   â”‚   â”œâ”€â”€ operations_kpis.py         #   Inventory, delivery, stockouts
â”‚   â”‚   â”œâ”€â”€ customer_kpis.py           #   CLV, RFM, new vs returning
â”‚   â”‚   â””â”€â”€ market_basket.py           #   Apriori association rules
â”‚   â”‚
â”‚   â””â”€â”€ api/                           # REST API backend
â”‚       â””â”€â”€ api.py                     #   FastAPI serving KPI JSON to dashboard
â”‚
â”œâ”€â”€ sql/                               # Standalone SQL queries
â”‚   â””â”€â”€ kpi_queries.sql                #   All KPI queries (DuckDB SQL)
â”‚
â”œâ”€â”€ dashboard/                         # Next.js 14 dashboard frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                       #   App Router pages (7 routes)
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx               #     ğŸ  Overview (home)
â”‚   â”‚   â”‚   â”œâ”€â”€ sales/                 #     ğŸ“Š Sales Analytics
â”‚   â”‚   â”‚   â”œâ”€â”€ inventory/             #     ğŸ“¦ Inventory Health
â”‚   â”‚   â”‚   â”œâ”€â”€ logistics/             #     ğŸšš Logistics
â”‚   â”‚   â”‚   â”œâ”€â”€ customers/             #     ğŸ‘¥ Customer Intelligence
â”‚   â”‚   â”‚   â”œâ”€â”€ market-basket/         #     ğŸ›’ Market Basket Analysis
â”‚   â”‚   â”‚   â””â”€â”€ data-quality/          #     âœ… Data Quality
â”‚   â”‚   â””â”€â”€ components/                #   Reusable UI components
â”‚   â”‚       â”œâ”€â”€ Sidebar.tsx            #     Navigation sidebar
â”‚   â”‚       â”œâ”€â”€ KpiCard.tsx            #     Metric display cards
â”‚   â”‚       â”œâ”€â”€ ChartCard.tsx          #     Chart wrapper
â”‚   â”‚       â”œâ”€â”€ PageHeader.tsx         #     Page titles
â”‚   â”‚       â””â”€â”€ Skeleton.tsx           #     Loading skeletons
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tailwind.config.ts
â”‚
â”œâ”€â”€ scripts/                           # One-click automation scripts
â”‚   â”œâ”€â”€ installation.sh                #   Full setup (venv + pip + npm)
â”‚   â”œâ”€â”€ generation.sh                  #   Generate synthetic data
â”‚   â”œâ”€â”€ ingestion.sh                   #   Ingest Raw â†’ Bronze
â”‚   â”œâ”€â”€ transform.sh                   #   Transform Bronze â†’ Silver â†’ Gold
â”‚   â”œâ”€â”€ kpi_analysis.sh                #   Run all KPI analytics
â”‚   â”œâ”€â”€ quality_checks.sh              #   Run data quality checks
â”‚   â”œâ”€â”€ api.sh                         #   Start FastAPI server
â”‚   â””â”€â”€ dashboard.sh                   #   Start Next.js dev server
â”‚
â”œâ”€â”€ docs/                              # Architecture & design documentation
â”‚   â”œâ”€â”€ architecture.md                #   Medallion Architecture deep-dive
â”‚   â”œâ”€â”€ architecture_diagram.png       #   Visual architecture diagram
â”‚   â”œâ”€â”€ data_quality.md                #   DQ rule catalog & thresholds
â”‚   â”œâ”€â”€ storage_security_plan.md       #   Partitioning, RBAC, encryption
â”‚   â””â”€â”€ STORAGE_AND_SECURITY.md        #   Security & compliance plan
â”‚
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                          # â† You are here
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+**
- **Node.js 18+** & npm
- **Git**

### 1. Clone & Install (one-time setup)

```bash
git clone https://github.com/ayushmaninbox/retail-data-hub.git
cd retail-data-hub
./scripts/installation.sh
```

> This creates a Python virtual environment, installs all pip dependencies, installs
> DuckDB, runs `npm install` for the dashboard, and creates the `data/` directories.

### 2. Run the Data Pipeline (Terminal 1)

Run each step sequentially to walk through the full Medallion Architecture:

```bash
# Step 1 â€” Generate synthetic raw data (CSV/JSON â†’ data/raw/)
./scripts/generation.sh

# Step 2 â€” Ingest into Bronze layer (Parquet â†’ data/bronze/)
./scripts/ingestion.sh

# Step 3 â€” Transform Bronze â†’ Silver â†’ Gold star schema
./scripts/transform.sh

# Step 4 â€” Compute all KPI analytics (JSON â†’ data/analytics/)
./scripts/kpi_analysis.sh

# Step 5 â€” Run data quality checks (â†’ data/data_quality_report.json)
./scripts/quality_checks.sh
```

### 3. Start the API Server (Terminal 2)

```bash
./scripts/api.sh
```

> ğŸŸ¢ FastAPI runs on **http://localhost:8000**
> ğŸ“š Interactive API docs at **http://localhost:8000/docs**

### 4. Start the Dashboard (Terminal 3)

```bash
./scripts/dashboard.sh
```

> ğŸŸ¢ Next.js dashboard on **http://localhost:3000**

---

## ğŸ–¥ï¸ Dashboard Pages

The dashboard is a **Next.js 14** app built with **TypeScript**, **Tailwind CSS**, and **Recharts**. It fetches live data from the FastAPI backend.

| # | Page | Route | What You'll See |
|---|---|---|---|
| 1 | ğŸ  **Overview** | `/` | Revenue, orders, customers, avg transaction KPI cards + revenue trend |
| 2 | ğŸ“Š **Sales Analytics** | `/sales` | City-wise sales, top products, channel mix, monthly trends |
| 3 | ğŸ“¦ **Inventory Health** | `/inventory` | Stockout alerts, turnover ratio, reorder recommendations |
| 4 | ğŸšš **Logistics** | `/logistics` | Avg delivery time, delay distribution, seasonal demand |
| 5 | ğŸ‘¥ **Customers** | `/customers` | New vs returning, CLV distribution, RFM segments |
| 6 | ğŸ›’ **Market Basket** | `/market-basket` | Item associations, confidence scores, recommendation pairs |
| 7 | âœ… **Data Quality** | `/data-quality` | Pipeline health, row counts, check pass/fail status |

---

## ğŸš€ API Endpoints

The FastAPI backend serves pre-computed KPI data from the Gold layer as JSON:

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/api/health` | Health check + data file status |
| `GET` | `/api/overview` | Combined summary for the Overview page |
| `GET` | `/api/commercial` | Revenue, city sales, top products, channel mix |
| `GET` | `/api/operations` | Inventory turnover, stockout rate, delivery times |
| `GET` | `/api/customers` | CLV, RFM segmentation, new vs returning |
| `GET` | `/api/market-basket` | Market Basket Analysis (Apriori) results |
| `GET` | `/api/data-quality` | Data quality report |
| `GET` | `/api/sales` | Sales-specific data (derived from commercial) |
| `GET` | `/api/inventory` | Inventory-specific data (derived from operations) |
| `GET` | `/api/logistics` | Logistics-specific data (derived from operations) |

---

## ğŸ”‘ Key KPIs

### ğŸ“ˆ Commercial
- Daily / monthly revenue aggregation
- City-wise sales breakdown (10 Indian cities)
- Top 10 products by quantity sold
- Channel mix â€” POS vs Web revenue split
- Category-level revenue analysis

### ğŸ“¦ Operations
- Inventory turnover ratio per product/store
- Average delivery time per route
- Stockout rate (% of products with zero stock)
- Seasonal demand trends (monthly quantity by category)
- Reorder point alerts

### ğŸ‘¥ Customer
- New vs returning customer counts
- Customer Lifetime Value (CLV)
- RFM segmentation (Recency Â· Frequency Â· Monetary)

### ğŸ›’ AI / ML
- Market basket analysis using **Apriori algorithm**
- Standard, cross-channel, and category-level association rules
- Support, confidence & lift scores

---

## ğŸ›¡ï¸ Data Quality Framework

Seven automated checks run at every pipeline stage:

| # | Check | Rule | On Failure |
|---|---|---|---|
| 1 | No negative prices | `unit_price >= 0` | Quarantine row |
| 2 | No future dates | `date <= today()` | Reject row |
| 3 | No null customer IDs | `customer_id IS NOT NULL` | Fill "UNKNOWN" |
| 4 | No duplicates | Composite key uniqueness | Drop duplicate |
| 5 | Referential integrity | FK exists in dimension | Reject orphan |
| 6 | Quantity range | `1 <= qty <= 10,000` | Flag outlier |
| 7 | Column completeness | `% non-null per column` | Report metric |

Results are saved as `data/data_quality_report.json` and visualized in the Data Quality dashboard page.

---

## ğŸ§° Tech Stack

| Layer | Technology |
|---|---|
| **Language** | Python 3.9+ Â· TypeScript |
| **Data Generation** | Faker, Pandas, NumPy |
| **Storage Format** | Apache Parquet (columnar, compressed) |
| **Query Engine** | DuckDB (in-process OLAP) |
| **Transformations** | Pandas, DuckDB SQL |
| **ML / Analytics** | mlxtend (Apriori), scikit-learn, Pandas |
| **API Backend** | FastAPI + Uvicorn |
| **Dashboard** | Next.js 14 + React 18 + TypeScript |
| **Charts** | Recharts |
| **Styling** | Tailwind CSS |
| **UI Components** | Lucide React (icons) |
| **Automation** | Shell scripts (Bash) |

---

## ğŸ“œ Scripts Reference

All scripts live in `scripts/` and auto-detect the project root + activate the virtual environment:

| Script | Purpose |
|---|---|
| `installation.sh` | Creates venv, installs Python deps + npm packages, sets up data dirs |
| `generation.sh` | Generates synthetic POS, Web Order, and Warehouse data |
| `ingestion.sh` | Ingests raw CSV/JSON into Bronze layer Parquet files |
| `transform.sh` | Runs Bronze â†’ Silver â†’ Gold transformations (incl. SCD2) |
| `kpi_analysis.sh` | Executes all 4 KPI analytics scripts, outputs JSON |
| `quality_checks.sh` | Runs 7 data quality checks, generates report |
| `api.sh` | Starts the FastAPI server on port 8000 |
| `dashboard.sh` | Starts the Next.js dev server on port 3000 |

---

## ğŸ“„ Documentation

Detailed docs live in the [`docs/`](docs/) directory:

| Document | Description |
|---|---|
| [architecture.md](docs/architecture.md) | Medallion Architecture deep-dive, design decisions, trade-offs |
| [architecture_diagram.png](docs/architecture_diagram.png) | Visual system architecture diagram |
| [data_quality.md](docs/data_quality.md) | Full DQ rule catalog, thresholds, and sample evidence |
| [storage_security_plan.md](docs/storage_security_plan.md) | Parquet partitioning strategy, RBAC, encryption, audit logging |

---

## ğŸ¯ Demo Flow (for Judges)

1. **Show empty `data/` folders** â€” *"We start from zero"*
2. **Run the pipeline** (Steps 1â€“5 in Terminal 1) â€” narrate each medallion layer
3. **Start API** (Terminal 2) â€” show Swagger docs at `/docs`
4. **Start Dashboard** (Terminal 3) â€” walk through all 7 pages
5. **Highlight the journey**: Raw CSV â†’ Parquet â†’ Star Schema â†’ KPIs â†’ REST API â†’ Dashboard

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“œ License

This project is built for a hackathon and is open for educational use.

---

<p align="center">
  Built with â¤ï¸ by <strong>Team SixSevenCoders</strong>
</p>
