# ðŸš€ Retail Data Hub â€” Demo Run Order

> All scripts are in `scripts/` and can be run from anywhere.
> Each script auto-detects the project root and activates the venv.

---

## ðŸ› ï¸ First Time Setup (one-time)

```bash
./scripts/installation.sh
```
> Creates venv, installs Python deps + DuckDB, runs npm install for dashboard

---

## ðŸ“Š TERMINAL 1 â€” Run Pipeline (sequential, one by one)

```bash
# Step 1: Generate Raw Data (CSV/JSON â†’ data/raw/)
./scripts/generation.sh

# Step 2: Ingest â†’ Bronze Layer (Parquet â†’ data/bronze/)
./scripts/ingestion.sh

# Step 3 & 4: Transform Bronze â†’ Silver â†’ Gold Star Schema
./scripts/transform.sh

# Step 5: Run KPI Analytics (JSON â†’ data/analytics/)
./scripts/kpi_analysis.sh

# Step 6: Data Quality Checks (â†’ data/data_quality_report.json)
./scripts/quality_checks.sh
```

---

## ðŸš€ TERMINAL 2 â€” Start API Server (keep running)

```bash
./scripts/api.sh
```
> ðŸŸ¢ FastAPI on http://localhost:8000 | Docs â†’ http://localhost:8000/docs

---

## ðŸ–¥ï¸ TERMINAL 3 â€” Start Dashboard (keep running)

```bash
./scripts/dashboard.sh
```
> ðŸŸ¢ Next.js on http://localhost:3000

---

## ðŸŽ¯ Demo Flow for Judges

1. **Show empty `data/` folders** â€” "We start from zero"
2. **Run Steps 1â€“6 in Terminal 1** â€” narrate each medallion layer
3. **Start API (Terminal 2)** â€” show Swagger docs briefly
4. **Start Dashboard (Terminal 3)** â€” walk through all 7 pages
5. **Highlight**: Raw CSV â†’ Parquet â†’ Star Schema â†’ KPIs â†’ API â†’ Dashboard